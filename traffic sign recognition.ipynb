{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traffic sign recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "assert sys.version_info >= (3,7)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import imutils\n",
    "import random\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For reproducibility,\n",
    "np.random.seed(99)\n",
    "\n",
    "# Make sure that optimization is enabled\n",
    "if not cv.useOptimized():\n",
    "    cv.setUseOptimized(True)\n",
    "cv.useOptimized()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Declare all modifiable variables for easier tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traffic signs with blue colour\n",
    "blue_ts = (20,21,22,23,24,25,26,27,28,29,30,31)\n",
    "\n",
    "# Traffic signs with red colour\n",
    "red_ts = (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,33,52,53,54,55,56,57)\n",
    "\n",
    "# Traffic signs with yellow colour\n",
    "yellow_ts = (18,19,32,34,335,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51)\n",
    "\n",
    "# All traffic signs\n",
    "all_ts = tuple(range(0, 58))\n",
    "\n",
    "# Bounderies for HSV thresholding, fine tuned to fit the dataset\n",
    "# Red colour segmentation\n",
    "lower_red, upper_red = (0, 25, 10), (10, 255, 255)\n",
    "lower_red2, upper_red2 = (150, 25, 0), (180, 255, 255)\n",
    "\n",
    "# Blue colour segmentation\n",
    "lower_blue, upper_blue = (90, 60, 10), (135, 255, 255)\n",
    "\n",
    "# Yellow colour segmentation\n",
    "lower_yellow, upper_yellow = (10, 50, 10), (55, 255, 255)\n",
    "lower_black, upper_black = (0, 0, 0), (180, 50, 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Create reusable functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hsv_edges_bg_mask(image):\n",
    "    image = cv.GaussianBlur(image, (5,5), 3)\n",
    "    h, w = image.shape[:2]\n",
    "    noise_mask = np.ones((h+2, w+2))\n",
    "    \n",
    "    \n",
    "    # Get the position to fill\n",
    "    left = int(w*0.1)\n",
    "    right = int(w*0.9)\n",
    "    top = int(h*0.1)\n",
    "    bottom = int(h*0.9)\n",
    "    \n",
    "    \n",
    "    # Get colour of edges\n",
    "    top_left_colour = image[top,left]\n",
    "    bottom_left_colour = image[bottom, left]\n",
    "    top_right_colour = image[top,right]\n",
    "    bottom_right_colour = image[bottom,right]\n",
    "    \n",
    "    \n",
    "    # Get all the noise of the background\n",
    "    mask = cv.inRange(image, top_left_colour - 7, top_left_colour + 7)\n",
    "    mask += cv.inRange(image, bottom_left_colour - 7, bottom_left_colour + 7)\n",
    "    mask += cv.inRange(image, top_right_colour - 7, top_right_colour + 7)\n",
    "    mask += cv.inRange(image, bottom_right_colour - 7, bottom_right_colour + 7)\n",
    "    \n",
    "    \n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def canny_seg(image, dilate_kernel1, dilate_kernel2, dilate_iterations):    \n",
    "    # Smoothing the image\n",
    "    image = cv.GaussianBlur(image, (7, 7), 1)\n",
    "    \n",
    "    \n",
    "    # Canny segmentation\n",
    "    mask = cv.Canny(image, 1, 100)\n",
    "    \n",
    "    \n",
    "    # Dilate the edges found by canny segmentation\n",
    "    mask = cv.dilate(mask, (dilate_kernel1,dilate_kernel2), iterations=dilate_iterations)\n",
    "    \n",
    "    \n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blue_seg(image_hsv, image_bgr, background_mask):\n",
    "    # Thresholding\n",
    "    mask = cv.inRange(image_hsv, lower_blue, upper_blue)\n",
    "    \n",
    "    # Removing edges\n",
    "    canny_mask = canny_seg(image_bgr, 3, 3, 2)\n",
    "    \n",
    "    \n",
    "    final_mask = mask - canny_mask - background_mask\n",
    "    \n",
    "    \n",
    "    return final_mask, mask, canny_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def red_seg(image_hsv, image_bgr, background_mask):\n",
    "    # Thresholding\n",
    "    mask = cv.inRange(image_hsv, lower_red, upper_red)\n",
    "    mask += cv.inRange(image_hsv, lower_red2, upper_red2)\n",
    "    \n",
    "    \n",
    "    # Removing edges\n",
    "    canny_mask = canny_seg(image_bgr, 1, 1, 1)\n",
    "    \n",
    "    \n",
    "    final_mask = mask - canny_mask - background_mask\n",
    "    \n",
    "    \n",
    "    return final_mask, mask, canny_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def black_seg(image_hsv, image_bgr, background_mask):\n",
    "    h,w = image_hsv.shape[:2]\n",
    "    \n",
    "    \n",
    "    # Segment the edges\n",
    "    canny_mask = canny_seg(image_bgr, 1, 1, 1)\n",
    "\n",
    "    \n",
    "    # edged is the edge detected image\n",
    "    cnts = cv.findContours(canny_mask, cv.RETR_LIST, cv.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "    cnts = sorted(cnts, key = cv.contourArea, reverse = True)[:5]\n",
    "    # loop over the contours\n",
    "    i = 0\n",
    "    for c in cnts:\n",
    "        if (cv.contourArea(c) < h * w * 0.10):\n",
    "            break\n",
    "\n",
    "        # approximate the contour\n",
    "        peri = cv.arcLength(c, True)\n",
    "        approx = cv.approxPolyDP(c, 0.1 * peri, True)\n",
    "        # Contour has 3 points, represents a triangle\n",
    "        if len(approx) == 3:\n",
    "            temp_mask = np.zeros(image_hsv.shape[:2], dtype = np.uint8)\n",
    "            cv.drawContours(temp_mask, cnts, i, (255,255,255), -1)\n",
    "            return temp_mask - background_mask, temp_mask, canny_mask\n",
    "        i+=1\n",
    "    \n",
    "    \n",
    "    mask = cv.inRange(image_hsv, lower_black, upper_black)\n",
    "    mask += cv.inRange(image_hsv, lower_yellow, upper_yellow)\n",
    "    \n",
    "    \n",
    "    final_mask = mask - canny_mask - background_mask\n",
    "    \n",
    "    \n",
    "    return final_mask, mask, canny_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_largest_contour(image, fill = -1):\n",
    "    # Threshold to keep only the bright area in the mask \n",
    "    _, image = cv.threshold(image, 200, 255, cv.THRESH_TOZERO)\n",
    "    \n",
    "    mask = np.zeros(image.shape, dtype = np.uint8)\n",
    "    largest_contour = None\n",
    "    \n",
    "    \n",
    "    # Find all contours\n",
    "    if (int(cv.__version__[0]) > 3):\n",
    "        contours, hierarchy = cv.findContours(image, cv.RETR_LIST, cv.CHAIN_APPROX_SIMPLE)\n",
    "    else:\n",
    "        _, contours, hierarchy = cv.findContours(image, cv.RETR_LIST, cv.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    \n",
    "    # Find and draw largest contour\n",
    "    if len(contours) != 0:\n",
    "        cnt_list = np.zeros(len(contours))\n",
    "        for i in range(0,len(contours)):\n",
    "            cnt_list[i] = cv.contourArea(contours[i])\n",
    "\n",
    "            \n",
    "        largest_contour_index = np.argmax(cnt_list)\n",
    "        largest_contour = contours[largest_contour_index]\n",
    "        cv.drawContours(mask, contours, largest_contour_index, (255,255,255), fill)\n",
    "\n",
    "        \n",
    "    return largest_contour, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bounding_box(image, largest_contour, colour):\n",
    "    bounding_box = image.copy()\n",
    "    \n",
    "    \n",
    "    # If contour is not exists\n",
    "    if (largest_contour is None):\n",
    "        return bounding_box, (0,0,0,0)\n",
    "    \n",
    "    \n",
    "    cv.boundingRect(largest_contour)\n",
    "    x,y,w,h = cv.boundingRect(largest_contour)\n",
    "    cv.rectangle(bounding_box,(x,y),(x+w,y+h),colour,2)\n",
    "    return bounding_box, (x,y,x+w,y+h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest_contour(contours, image):\n",
    "    h, w = image.shape[:2]\n",
    "    center = np.array((int(h/2), int(w/2)))\n",
    "    rect = np.zeros((h, w), dtype = np.uint8)\n",
    "    \n",
    "    \n",
    "    closest = 0\n",
    "    closest_distance = 9999\n",
    "    \n",
    "    \n",
    "    if(contours[0] is not None):\n",
    "        blue_dist = cv.moments(contours[0])\n",
    "        cx = int(blue_dist['m10']/max(blue_dist['m00'], 1))\n",
    "        cy = int(blue_dist['m01']/max(blue_dist['m00'], 1))\n",
    "        blue_distance = ((cx - center[1])**2 + (cy - center[0])**2)**0.5\n",
    "        if blue_distance < closest_distance:\n",
    "            _,_,w0,y0 = cv.boundingRect(contours[0])\n",
    "            if(w0*y0 > h*w*0.2):\n",
    "                closest_distance = blue_distance\n",
    "    \n",
    "    \n",
    "    if(contours[1] is not None):\n",
    "        red_dist = cv.moments(contours[1])\n",
    "        cx = int(red_dist['m10']/max(red_dist['m00'], 1))\n",
    "        cy = int(red_dist['m01']/max(red_dist['m00'], 1))\n",
    "        red_distance = ((cx - center[1])**2 + (cy - center[0])**2)**0.5\n",
    "        if red_distance < closest_distance:\n",
    "            _,_,w1,y1 = cv.boundingRect(contours[1])\n",
    "            if(w1*y1 > h*w*0.2):\n",
    "                closest = 1\n",
    "                closest_distance = red_distance\n",
    "        \n",
    "        \n",
    "    if(contours[2] is not None):\n",
    "        yellow_dist = cv.moments(contours[2])\n",
    "        cx = int(yellow_dist['m10']/max(yellow_dist['m00'], 1))\n",
    "        cy = int(yellow_dist['m01']/max(yellow_dist['m00'], 1))\n",
    "        yellow_distance = ((cx - center[1])**2 + (cy - center[0])**2)**0.5\n",
    "        if yellow_distance < closest_distance:\n",
    "            _,_,w2,y2 = cv.boundingRect(contours[2])\n",
    "            if(w2*y2 > h*w*0.2):\n",
    "                closest = 2\n",
    "        \n",
    "    \n",
    "    return closest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shape_detection(image):\n",
    "    h,w = image.shape[:2]\n",
    "    mask = np.zeros((h, w), dtype = np.uint8)\n",
    "\n",
    "    \n",
    "    # Segment the edges\n",
    "    canny_mask = canny_seg(image, 1, 1, 1)\n",
    "    \n",
    "    \n",
    "    gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # detect circles\n",
    "    circles = cv.HoughCircles(gray, cv.HOUGH_GRADIENT, 1, 100, param1 = 50, param2 = 25, minRadius=int(w*0.2), maxRadius=int(w*0.4))\n",
    "\n",
    "    \n",
    "    # draw largest circle\n",
    "    if circles is not None:\n",
    "        circles=sorted(circles[0],key=lambda x:x[2],reverse=True)\n",
    "        circles = np.uint8(np.around(circles))\n",
    "        for i in circles:\n",
    "            center = (i[0], i[1])\n",
    "            # circle outline\n",
    "            radius = i[2]\n",
    "            cv.circle(mask, center, radius, 255, 2)\n",
    "    \n",
    "    final_mask = mask\n",
    "    \n",
    "    \n",
    "    return final_mask, mask, canny_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentation(annotation, images, traffic_sign, save_result):\n",
    "    seconds = time.time()\n",
    "    ts = np.where(annotation['Category'].isin(traffic_sign))[0]\n",
    "    combine_all = np.empty((150,1050,3))\n",
    "    bounding_box_points = []\n",
    "    \n",
    "    for i in range (len(ts)):\n",
    "        # Create a copy of the original image\n",
    "        image = images[ts[i]].copy()\n",
    "        h, w = image.shape[:2]\n",
    "        \n",
    "        \n",
    "        # Convert image into hsv colour space and gray colour space\n",
    "        image_hsv = cv.cvtColor(image, cv.COLOR_BGR2HSV)\n",
    "\n",
    "        \n",
    "        # Segment background colour\n",
    "        background_mask = hsv_edges_bg_mask(image_hsv)\n",
    " \n",
    "        if True:\n",
    "            # HSV segmentation\n",
    "            blueseg_mask, blue_mask, blue_canny_mask = blue_seg(image_hsv, image, background_mask)\n",
    "            redseg_mask, red_mask, red_canny_mask = red_seg(image_hsv, image, background_mask)\n",
    "            yellowseg_mask, yellow_mask, yellow_canny_mask = black_seg(image_hsv, image, background_mask)\n",
    "\n",
    "\n",
    "            # Find largest contour\n",
    "            blue_largest_contour, blue_largest_contour_mask = find_largest_contour(blueseg_mask)\n",
    "            red_largest_contour, red_largest_contour_mask = find_largest_contour(redseg_mask)\n",
    "            yellow_largest_contour, yellow_largest_contour_mask = find_largest_contour(yellowseg_mask)\n",
    "\n",
    "\n",
    "            # Draw bounding box\n",
    "            blue_bounding_box, blue_box_points = draw_bounding_box(image, blue_largest_contour, (0,255,0))\n",
    "            red_bounding_box, red_box_points = draw_bounding_box(image, red_largest_contour, (0,255,0))\n",
    "            yellow_bounding_box, yellow_box_points = draw_bounding_box(image, yellow_largest_contour, (0,255,0))\n",
    "\n",
    "\n",
    "            # Find the contour the is closest to the center\n",
    "            contours = [blue_largest_contour, red_largest_contour, yellow_largest_contour]\n",
    "            closest = closest_contour(contours, image)\n",
    "\n",
    "\n",
    "            if(closest == 0):\n",
    "                canny_mask = blue_canny_mask\n",
    "                hsv_mask = blue_mask\n",
    "                segmented_mask = blueseg_mask\n",
    "                final_mask = blue_largest_contour_mask\n",
    "                bounding_box = blue_bounding_box\n",
    "                bounding_box_points.append(blue_box_points)\n",
    "            elif (closest == 1):\n",
    "                canny_mask = red_canny_mask\n",
    "                hsv_mask = red_mask\n",
    "                segmented_mask = redseg_mask\n",
    "                final_mask = red_largest_contour_mask\n",
    "                bounding_box = red_bounding_box\n",
    "                bounding_box_points.append(red_box_points)\n",
    "            else:\n",
    "                canny_mask = yellow_canny_mask\n",
    "                hsv_mask = yellow_mask\n",
    "                segmented_mask = yellowseg_mask\n",
    "                final_mask = yellow_largest_contour_mask\n",
    "                bounding_box = yellow_bounding_box\n",
    "                bounding_box_points.append(yellow_box_points)\n",
    "        \n",
    "        else:\n",
    "            shape_largest_contour, shape_largest_contour_mask = find_largest_contour(shapeseg_mask)\n",
    "            shape_bounding_box, shape_box_points = draw_bounding_box(image, shape_largest_contour, (0,255,0))\n",
    "            \n",
    "            canny_mask = shape_canny_mask\n",
    "            hsv_mask = shape_mask\n",
    "            segmented_mask = shapeseg_mask\n",
    "            \n",
    "            \n",
    "            final_mask = shape_largest_contour_mask\n",
    "            bounding_box = shape_bounding_box\n",
    "            bounding_box_points.append(shape_box_points)\n",
    "\n",
    "\n",
    "        if(save_result):\n",
    "            canny_mask = np.stack((canny_mask,)*3, axis=-1)\n",
    "            background_mask = np.stack((background_mask,)*3, axis=-1)\n",
    "            hsv_mask = np.stack((hsv_mask,)*3, axis=-1)\n",
    "            segmented_mask = np.stack((segmented_mask,)*3, axis=-1)\n",
    "            final_mask = np.stack((final_mask,)*3, axis=-1)\n",
    "            combine = np.concatenate((image, canny_mask, background_mask, hsv_mask, segmented_mask, final_mask, bounding_box), axis = 1)\n",
    "            combine = cv.resize(combine, (1050,150), interpolation = cv.INTER_AREA)\n",
    "            \n",
    "            combine = np.concatenate((np.zeros((30, 1050, 3)), combine), axis = 0)\n",
    "            cv.putText(combine, (\"original image\"), (5, 15), 0, 0.5, (255,255,255), 1, cv.LINE_AA)\n",
    "            cv.putText(combine, (\"edges detected\"), (155, 15), 0, 0.5, (255,255,255), 1, cv.LINE_AA)\n",
    "            cv.putText(combine, (\"background\"), (305, 15), 0, 0.5, (255,255,255), 1, cv.LINE_AA)\n",
    "            cv.putText(combine, (\"HSV mask\"), (455, 15), 0, 0.5, (255,255,255), 1, cv.LINE_AA)\n",
    "            cv.putText(combine, (\"segmentation\"), (605, 15), 0, 0.5, (255,255,255), 1, cv.LINE_AA)\n",
    "            cv.putText(combine, (\"largest contour\"), (755, 15), 0, 0.5, (255,255,255), 1, cv.LINE_AA)\n",
    "            cv.putText(combine, (\"bounding box\"), (905, 15), 0, 0.5, (255,255,255), 1, cv.LINE_AA)\n",
    "            \n",
    "            combine_all = np.concatenate((combine_all, combine), axis = 0)      \n",
    "            if (i%100 == 0):\n",
    "                cv.imwrite('saved' + str(i//100) + '.jpg', combine_all)\n",
    "                combine_all = combine\n",
    "                print(i, \"/\", len(ts), \"Elapsed time:\", time.time() - seconds, \"Average time:\", (time.time() - seconds)/(i+1))\n",
    "        elif (i%100 == 0):\n",
    "            print(i, \"/\", len(ts), \"Elapsed time:\", time.time() - seconds, \"Average time:\", (time.time() - seconds)/(i+1))\n",
    "    \n",
    "    return bounding_box_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Load train annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the train set annotation txt file\n",
    "path = os.path.join(os.getcwd(), 'TSRD-Train Annotation\\\\TsignRecgTrain4170Annotation.txt')\n",
    "\n",
    "# Name of the columns\n",
    "columns = ['File Name', 'Width', 'Height', 'Start_X', 'Start_Y', 'End_X', 'End_Y', 'Category']\n",
    "\n",
    "# Read the content of the train annotation txt file into train_annotation\n",
    "train_annotation = pd.read_csv(path, sep=\";\", index_col = False, names = columns)\n",
    "\n",
    "# Category of the images\n",
    "train_category = train_annotation['Category'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Load train images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path to the folder containing the trains set image files\n",
    "path = os.path.join(os.getcwd(), 'TSRD-train')\n",
    "\n",
    "#read the train images into train_image\n",
    "train_images = []\n",
    "for i in range (train_annotation.shape[0]):\n",
    "    train_images.append(cv.imread(path + '\\\\' + train_annotation.iloc[i][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 4170 Elapsed time: 0.004998445510864258 Average time: 0.004998445510864258\n",
      "100 / 4170 Elapsed time: 0.25797367095947266 Average time: 0.0025541947619749767\n",
      "200 / 4170 Elapsed time: 0.44406962394714355 Average time: 0.002209301611677331\n",
      "300 / 4170 Elapsed time: 0.6384623050689697 Average time: 0.0021211372261427564\n",
      "400 / 4170 Elapsed time: 0.8795437812805176 Average time: 0.002193376013168373\n",
      "500 / 4170 Elapsed time: 1.0844290256500244 Average time: 0.002164528993313422\n",
      "600 / 4170 Elapsed time: 1.335904836654663 Average time: 0.0022228033887764778\n",
      "700 / 4170 Elapsed time: 1.594414234161377 Average time: 0.002274485355437057\n",
      "800 / 4170 Elapsed time: 1.8116679191589355 Average time: 0.0022617577018213928\n",
      "900 / 4170 Elapsed time: 2.02583646774292 Average time: 0.0022484311517679467\n",
      "1000 / 4170 Elapsed time: 2.3538689613342285 Average time: 0.002351517443890338\n",
      "1100 / 4170 Elapsed time: 2.5972237586975098 Average time: 0.002358967991550872\n",
      "1200 / 4170 Elapsed time: 2.7923078536987305 Average time: 0.002324985723312848\n",
      "1300 / 4170 Elapsed time: 3.1579320430755615 Average time: 0.002427311332110347\n",
      "1400 / 4170 Elapsed time: 3.618364095687866 Average time: 0.002582700996208327\n",
      "1500 / 4170 Elapsed time: 4.019596338272095 Average time: 0.0026779455951179846\n",
      "1600 / 4170 Elapsed time: 4.454421043395996 Average time: 0.0027822742307282923\n",
      "1700 / 4170 Elapsed time: 4.843062162399292 Average time: 0.00284718528065802\n",
      "1800 / 4170 Elapsed time: 5.322319030761719 Average time: 0.0029552021270192776\n",
      "1900 / 4170 Elapsed time: 5.7955663204193115 Average time: 0.0030486934878586596\n",
      "2000 / 4170 Elapsed time: 6.25580096244812 Average time: 0.003126337312567776\n",
      "2100 / 4170 Elapsed time: 6.73146915435791 Average time: 0.0032039358183521705\n",
      "2200 / 4170 Elapsed time: 7.19752311706543 Average time: 0.0032701150009384053\n",
      "2300 / 4170 Elapsed time: 7.6655988693237305 Average time: 0.0033314206298668972\n",
      "2400 / 4170 Elapsed time: 8.159376621246338 Average time: 0.003398324290398308\n",
      "2500 / 4170 Elapsed time: 8.659602642059326 Average time: 0.003462456074393973\n",
      "2600 / 4170 Elapsed time: 9.193283319473267 Average time: 0.003534518769501448\n",
      "2700 / 4170 Elapsed time: 9.635854244232178 Average time: 0.0035675136039363857\n",
      "2800 / 4170 Elapsed time: 10.19319748878479 Average time: 0.003639127985999568\n",
      "2900 / 4170 Elapsed time: 10.610062837600708 Average time: 0.0036573811918651183\n",
      "3000 / 4170 Elapsed time: 11.166727304458618 Average time: 0.003721002100785944\n",
      "3100 / 4170 Elapsed time: 11.713994979858398 Average time: 0.00377748951301464\n",
      "3200 / 4170 Elapsed time: 12.22589659690857 Average time: 0.003819399124307582\n",
      "3300 / 4170 Elapsed time: 12.740951538085938 Average time: 0.003859724791907282\n",
      "3400 / 4170 Elapsed time: 13.207206726074219 Average time: 0.003883330410489332\n",
      "3500 / 4170 Elapsed time: 13.700260877609253 Average time: 0.003913242181550772\n",
      "3600 / 4170 Elapsed time: 14.159364700317383 Average time: 0.0039320646210267655\n",
      "3700 / 4170 Elapsed time: 14.624417543411255 Average time: 0.0039514773151611065\n",
      "3800 / 4170 Elapsed time: 15.07751727104187 Average time: 0.00396672382821412\n",
      "3900 / 4170 Elapsed time: 15.660646438598633 Average time: 0.004014521004511313\n",
      "4000 / 4170 Elapsed time: 16.160215377807617 Average time: 0.004039044083431046\n",
      "4100 / 4170 Elapsed time: 16.58208441734314 Average time: 0.004043424632368481\n"
     ]
    }
   ],
   "source": [
    "bounding_box_points = segmentation(train_annotation, train_images, all_ts, save_result = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Segmentation Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation accuracy for train set: 0.9010446792760016\n"
     ]
    }
   ],
   "source": [
    "total_overlapp = 0\n",
    "area = 0\n",
    "for i in range (len(bounding_box_points)):\n",
    "    area1 = (bounding_box_points[i][2] - bounding_box_points[i][0]) * (bounding_box_points[i][3] - bounding_box_points[i][1])\n",
    "    area2 = (train_annotation['End_X'][i] - train_annotation['Start_X'][i]) * (train_annotation['End_Y'][i] - train_annotation['Start_Y'][i])\n",
    "    X_diff = max(0, min(bounding_box_points[i][2], train_annotation['End_X'][i]) - max(bounding_box_points[i][0], train_annotation['Start_X'][i]))\n",
    "    Y_diff = max(0, min(bounding_box_points[i][3], train_annotation['End_Y'][i]) - max(bounding_box_points[i][1], train_annotation['Start_Y'][i]))\n",
    "    overlapp = X_diff * Y_diff\n",
    "    total_overlapp += overlapp\n",
    "    area = area + area1 + area2 - overlapp\n",
    "print(\"Segmentation accuracy for train set:\", total_overlapp/area)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Split train and val set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the samples according to class\n",
    "sorted_array = sorted(enumerate(train_category), key=lambda x: x[1])\n",
    "sorted_indices = [index for index, _ in sorted_array]\n",
    "\n",
    "# split train:val according to the ratio\n",
    "val_ratio = 0.1\n",
    "\n",
    "# calculate number of val samples in each class\n",
    "class_count = [0]\n",
    "for i in range (len(train_category)):\n",
    "    if(train_category[i] >= len(class_count)):\n",
    "        class_count.append(0)\n",
    "    class_count[train_category[i]] += 1\n",
    "    \n",
    "# split train and val set\n",
    "train_set = []\n",
    "val_set = []\n",
    "random.seed(42)\n",
    "prev_samples = 0\n",
    "for i in range (len(class_count)):\n",
    "    class_val_count = int(class_count[i] * val_ratio)\n",
    "    val_set_index = []\n",
    "    marked = [False] * class_count[i]\n",
    "    for j in range(class_val_count):\n",
    "        selected = random.randint(0, class_count[i] - 1)\n",
    "        while (marked[selected]):\n",
    "            selected += 1\n",
    "            if selected == class_val_count:\n",
    "                selected = 0\n",
    "        marked[selected] = True\n",
    "    for j in range (len(marked)):\n",
    "        if(marked[j]):\n",
    "            val_set.append(sorted_indices[prev_samples + j])\n",
    "        else:\n",
    "            train_set.append(sorted_indices[prev_samples + j])\n",
    "    prev_samples += class_count[i]\n",
    "\n",
    "# shuffle the train and val sets\n",
    "random.shuffle(train_set)\n",
    "random.shuffle(val_set)\n",
    "\n",
    "# create train and val set samples and labels\n",
    "train_set_images = []\n",
    "train_set_cat = []\n",
    "val_set_images = []\n",
    "val_set_cat = []\n",
    "for i in range(len(train_set)):\n",
    "    ind = train_set[i]\n",
    "    train_set_images.append(train_images[ind][train_annotation['Start_Y'][ind]:train_annotation['End_Y'][ind], train_annotation['Start_X'][ind]:train_annotation['End_X'][ind]])\n",
    "    train_set_cat.append(train_category[ind])\n",
    "\n",
    "for i in range(len(val_set)):\n",
    "    ind = val_set[i]\n",
    "    val_set_images.append(train_images[ind][bounding_box_points[ind][1]:bounding_box_points[ind][3], bounding_box_points[ind][0]:bounding_box_points[ind][2]])\n",
    "    val_set_cat.append(train_category[ind])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. Feature extraction using HOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "winSize = (128, 128)\n",
    "blockSize = (16, 16)\n",
    "blockStride = (8, 8)\n",
    "cellSize = (8, 8)\n",
    "nbins = 9\n",
    "hog = cv.HOGDescriptor(winSize, blockSize, blockStride, cellSize, nbins)\n",
    "\n",
    "def feature_extraction(image):\n",
    "    # preprocessing\n",
    "    image_size = (128, 128)\n",
    "    image = cv.resize(image, image_size)\n",
    "    gray_image = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Compute HOG features\n",
    "    features = hog.compute(gray_image)\n",
    "\n",
    "    # Reshape the feature vector\n",
    "    features = np.reshape(features, (-1))\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11. Train SVM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features for train set...\n",
      "Extracting features for val set...\n",
      "Training classifier...\n",
      "Predicting train set...\n",
      "Calculating train set accuracy...\n",
      "Correct prediction:  3776 / 3776\n",
      "Accuracy score:  1.0\n",
      "\n",
      "Predicting val set...\n",
      "Calculating val accuracy...\n",
      "Correct prediction:  371 / 394\n",
      "Accuracy score:  0.9416243654822335\n"
     ]
    }
   ],
   "source": [
    "# Extract Features\n",
    "train_set_features = []\n",
    "val_set_features = []\n",
    "print(\"Extracting features for train set...\")\n",
    "for i in range(len(train_set_images)):\n",
    "    train_set_features.append(feature_extraction(train_set_images[i]))\n",
    "if len(val_set_images) > 0:\n",
    "    print(\"Extracting features for val set...\")\n",
    "    for i in range(len(val_set_images)):\n",
    "        val_set_features.append(feature_extraction(val_set_images[i]))\n",
    "train_set_features = np.array(train_set_features)\n",
    "val_set_features = np.array(val_set_features)\n",
    "\n",
    "# Normalization\n",
    "scaler = StandardScaler()\n",
    "train_set_features = scaler.fit_transform(train_set_features)\n",
    "if len(val_set_images) > 0:\n",
    "    val_set_features = scaler.transform(val_set_features)\n",
    "\n",
    "# Train the SVM classifier\n",
    "print(\"Training classifier...\")\n",
    "classifier = svm.SVC()\n",
    "classifier.fit(train_set_features, train_set_cat)\n",
    "\n",
    "# get training accuracy\n",
    "print(\"Predicting train set...\")\n",
    "predicted_train_classes = classifier.predict(train_set_features)\n",
    "print(\"Calculating train set accuracy...\")\n",
    "train_accuracy = accuracy_score(train_set_cat, predicted_train_classes)\n",
    "print(\"Correct prediction: \", int(len(predicted_train_classes) * train_accuracy), \"/\", len(predicted_train_classes))\n",
    "print(\"Accuracy score: \", train_accuracy)\n",
    "\n",
    "#get val accuracy\n",
    "if len(val_set_images) > 0:\n",
    "    print(\"\\nPredicting val set...\")\n",
    "    predicted_val_classes = classifier.predict(val_set_features)\n",
    "    print(\"Calculating val accuracy...\")\n",
    "    val_accuracy = accuracy_score(val_set_cat, predicted_val_classes)\n",
    "    print(\"Correct prediction: \", int(len(predicted_val_classes) * val_accuracy), \"/\", len(predicted_val_classes))\n",
    "    print(\"Accuracy score: \", val_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 12. Segmentation and classification evaluation with test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the train set annotation txt file\n",
    "path = os.path.join(os.getcwd(), 'TSRD-Test Annotation\\\\TsignRecgTest1994Annotation.txt')\n",
    "\n",
    "# Name of the columns\n",
    "columns = ['File Name', 'Width', 'Height', 'Start_X', 'Start_Y', 'End_X', 'End_Y', 'Category']\n",
    "\n",
    "# Read the content of the train annotation txt file into train_annotation\n",
    "test_annotation = pd.read_csv(path, sep=\";\", index_col = False, names = columns)\n",
    "\n",
    "# Category of the images\n",
    "test_category = test_annotation['Category'].values\n",
    "\n",
    "#path to the folder containing the trains set image files\n",
    "path = os.path.join(os.getcwd(), 'TSRD-test')\n",
    "\n",
    "#read the train images into train_image\n",
    "test_images = []\n",
    "for i in range (test_annotation.shape[0]):\n",
    "    test_images.append(cv.imread(path + '\\\\' + test_annotation.iloc[i][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 1994 Elapsed time: 0.0029449462890625 Average time: 0.0029449462890625\n",
      "100 / 1994 Elapsed time: 0.26861071586608887 Average time: 0.0026595120382781074\n",
      "200 / 1994 Elapsed time: 0.5595118999481201 Average time: 0.0027836412932742294\n",
      "300 / 1994 Elapsed time: 0.8564953804016113 Average time: 0.0028454996026631607\n",
      "400 / 1994 Elapsed time: 1.193113088607788 Average time: 0.0029753443606179253\n",
      "500 / 1994 Elapsed time: 1.5939459800720215 Average time: 0.003181528902339364\n",
      "600 / 1994 Elapsed time: 1.9804935455322266 Average time: 0.003295330358622673\n",
      "700 / 1994 Elapsed time: 2.3104562759399414 Average time: 0.0032959433322966355\n",
      "800 / 1994 Elapsed time: 2.6508922576904297 Average time: 0.0033094784740205115\n",
      "900 / 1994 Elapsed time: 3.0414483547210693 Average time: 0.0033756363537414753\n",
      "1000 / 1994 Elapsed time: 3.38366961479187 Average time: 0.0033802893254664037\n",
      "1100 / 1994 Elapsed time: 3.790205955505371 Average time: 0.003442512221167458\n",
      "1200 / 1994 Elapsed time: 4.152076721191406 Average time: 0.0034571829485357253\n",
      "1300 / 1994 Elapsed time: 4.413534164428711 Average time: 0.0033924167289997777\n",
      "1400 / 1994 Elapsed time: 4.837146997451782 Average time: 0.00345263882758871\n",
      "1500 / 1994 Elapsed time: 5.273413181304932 Average time: 0.0035132666097967566\n",
      "1600 / 1994 Elapsed time: 5.6065709590911865 Average time: 0.0035019181505878743\n",
      "1700 / 1994 Elapsed time: 5.99437403678894 Average time: 0.0035240294161016698\n",
      "1800 / 1994 Elapsed time: 6.353962421417236 Average time: 0.0035280191123915803\n",
      "1900 / 1994 Elapsed time: 6.72393012046814 Average time: 0.003537048984991131\n"
     ]
    }
   ],
   "source": [
    "# segmentate test set\n",
    "bounding_box_points = segmentation(test_annotation, test_images, all_ts, save_result = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation accuracy for test set: 0.763304833157623\n"
     ]
    }
   ],
   "source": [
    "total_overlapp = 0\n",
    "area = 0\n",
    "for i in range (len(bounding_box_points)):\n",
    "    area1 = (bounding_box_points[i][2] - bounding_box_points[i][0]) * (bounding_box_points[i][3] - bounding_box_points[i][1])\n",
    "    area2 = (test_annotation['End_X'][i] - test_annotation['Start_X'][i]) * (test_annotation['End_Y'][i] - test_annotation['Start_Y'][i])\n",
    "    X_diff = max(0, min(bounding_box_points[i][2], test_annotation['End_X'][i]) - max(bounding_box_points[i][0], test_annotation['Start_X'][i]))\n",
    "    Y_diff = max(0, min(bounding_box_points[i][3], test_annotation['End_Y'][i]) - max(bounding_box_points[i][1], test_annotation['Start_Y'][i]))\n",
    "    overlapp = X_diff * Y_diff\n",
    "    total_overlapp += overlapp\n",
    "    area = area + area1 + area2 - overlapp\n",
    "print(\"Segmentation accuracy for test set:\", total_overlapp/area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting test features\n",
      "Predicting test set...\n",
      "Calculating test set accuracy...\n",
      "Correct prediction - with proposed segmentation method:  1404 / 1994\n",
      "Accuracy score - with proposed segmentation method:  0.7041123370110332\n",
      "Correct prediction - ground:  1920 / 1994\n",
      "Accuracy score - ground:  0.9628886659979939\n"
     ]
    }
   ],
   "source": [
    "print(\"Extracting test features\")\n",
    "test_set_images = []\n",
    "test_set_images_ground = []\n",
    "test_set_cat = []\n",
    "test_set_features = []\n",
    "test_set_features_ground = []\n",
    "for i in range(len(test_images)):\n",
    "    if(bounding_box_points[i][0] != 0 and bounding_box_points[i][1] != 0 and bounding_box_points[i][2] != 0 and bounding_box_points[i][3] != 0):\n",
    "        test_set_images.append(test_images[i][bounding_box_points[i][1]:bounding_box_points[i][3], bounding_box_points[i][0]:bounding_box_points[i][2]])\n",
    "    else:\n",
    "        test_set_images.append(test_images[i])\n",
    "    test_set_images_ground.append(test_images[i][test_annotation['Start_Y'][i]:test_annotation['End_Y'][i], test_annotation['Start_X'][i]:test_annotation['End_X'][i]])\n",
    "    test_set_cat.append(test_category[i])\n",
    "    test_set_features.append(feature_extraction(test_set_images[i]))\n",
    "    test_set_features_ground.append(feature_extraction(test_set_images_ground[i]))\n",
    "test_set_features = scaler.transform(test_set_features)\n",
    "test_set_features_ground = scaler.transform(test_set_features_ground)\n",
    "\n",
    "print(\"Predicting test set...\")\n",
    "predicted_test_classes = classifier.predict(test_set_features)\n",
    "predicted_test_ground_classes = classifier.predict(test_set_features_ground)\n",
    "# print(predicted_test_classes)\n",
    "print(\"Calculating test set accuracy...\")\n",
    "test_accuracy = accuracy_score(test_set_cat, predicted_test_classes)\n",
    "test_accuracy_ground = accuracy_score(test_set_cat, predicted_test_ground_classes)\n",
    "print(\"Correct prediction - with proposed segmentation method: \", int(len(predicted_test_classes) * test_accuracy), \"/\", len(predicted_test_classes))\n",
    "print(\"Accuracy score - with proposed segmentation method: \", test_accuracy)\n",
    "print(\"Correct prediction - ground: \", int(len(predicted_test_ground_classes) * test_accuracy_ground), \"/\", len(predicted_test_classes))\n",
    "print(\"Accuracy score - ground: \", test_accuracy_ground)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
