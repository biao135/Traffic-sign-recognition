{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traffic sign recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "assert sys.version_info >= (3,7)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import imutils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For reproducibility,\n",
    "np.random.seed(99)\n",
    "\n",
    "# Make sure that optimization is enabled\n",
    "if not cv.useOptimized():\n",
    "    cv.setUseOptimized(True)\n",
    "cv.useOptimized()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Declare all modifiable variables for easier tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traffic signs with blue colour\n",
    "blue_ts = (20,21,22,23,24,25,26,27,28,29,30,31)\n",
    "\n",
    "# Traffic signs with red colour\n",
    "red_ts = (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,33,52,53,54,55,56,57)\n",
    "\n",
    "# Traffic signs with yellow colour\n",
    "yellow_ts = (18,19,32,34,335,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51)\n",
    "\n",
    "# All traffic signs\n",
    "all_ts = tuple(range(0, 58))\n",
    "\n",
    "# Bounderies for HSV thresholding, fine tuned to fit the dataset\n",
    "# Red colour segmentation\n",
    "lower_red, upper_red = (0, 25, 10), (10, 255, 255)\n",
    "lower_red2, upper_red2 = (150, 25, 0), (180, 255, 255)\n",
    "\n",
    "# Blue colour segmentation\n",
    "lower_blue, upper_blue = (90, 60, 10), (135, 255, 255)\n",
    "\n",
    "# Yellow colour segmentation\n",
    "lower_yellow, upper_yellow = (10, 50, 10), (55, 255, 255)\n",
    "lower_black, upper_black = (0, 0, 0), (180, 50, 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Create reusable functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hsv_edges_bg_mask(image):\n",
    "    image = cv.GaussianBlur(image, (5,5), 3)\n",
    "    h, w = image.shape[:2]\n",
    "    noise_mask = np.ones((h+2, w+2))\n",
    "    \n",
    "    \n",
    "    # Get the position to fill\n",
    "    left = int(w*0.1)\n",
    "    right = int(w*0.9)\n",
    "    top = int(h*0.1)\n",
    "    bottom = int(h*0.9)\n",
    "    \n",
    "    \n",
    "    # Get colour of edges\n",
    "    top_left_colour = image[top,left]\n",
    "    bottom_left_colour = image[bottom, left]\n",
    "    top_right_colour = image[top,right]\n",
    "    bottom_right_colour = image[bottom,right]\n",
    "    \n",
    "    \n",
    "    # Get all the noise of the background\n",
    "    mask = cv.inRange(image, top_left_colour - 7, top_left_colour + 7)\n",
    "    mask += cv.inRange(image, bottom_left_colour - 7, bottom_left_colour + 7)\n",
    "    mask += cv.inRange(image, top_right_colour - 7, top_right_colour + 7)\n",
    "    mask += cv.inRange(image, bottom_right_colour - 7, bottom_right_colour + 7)\n",
    "    \n",
    "    \n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def canny_seg(image, dilate_kernel1, dilate_kernel2, dilate_iterations):    \n",
    "    # Smoothing the image\n",
    "    image = cv.GaussianBlur(image, (7, 7), 1)\n",
    "    \n",
    "    \n",
    "    # Canny segmentation\n",
    "    mask = cv.Canny(image, 1, 100)\n",
    "    \n",
    "    \n",
    "    # Dilate the edges found by canny segmentation\n",
    "    mask = cv.dilate(mask, (dilate_kernel1,dilate_kernel2), iterations=dilate_iterations)\n",
    "    \n",
    "    \n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blue_seg(image_hsv, image_bgr, background_mask):\n",
    "    # Thresholding\n",
    "    mask = cv.inRange(image_hsv, lower_blue, upper_blue)\n",
    "    \n",
    "    # Removing edges\n",
    "    canny_mask = canny_seg(image_bgr, 3, 3, 2)\n",
    "    \n",
    "    \n",
    "    final_mask = mask - canny_mask - background_mask\n",
    "    \n",
    "    \n",
    "    return final_mask, mask, canny_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def red_seg(image_hsv, image_bgr, background_mask):\n",
    "    # Thresholding\n",
    "    mask = cv.inRange(image_hsv, lower_red, upper_red)\n",
    "    mask += cv.inRange(image_hsv, lower_red2, upper_red2)\n",
    "    \n",
    "    \n",
    "    # Removing edges\n",
    "    canny_mask = canny_seg(image_bgr, 1, 1, 1)\n",
    "    \n",
    "    \n",
    "    final_mask = mask - canny_mask - background_mask\n",
    "    \n",
    "    \n",
    "    return final_mask, mask, canny_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def black_seg(image_hsv, image_bgr, background_mask):\n",
    "    h,w = image_hsv.shape[:2]\n",
    "    \n",
    "    \n",
    "    # Segment the edges\n",
    "    canny_mask = canny_seg(image_bgr, 1, 1, 1)\n",
    "\n",
    "    \n",
    "    # edged is the edge detected image\n",
    "    cnts = cv.findContours(canny_mask, cv.RETR_LIST, cv.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "    cnts = sorted(cnts, key = cv.contourArea, reverse = True)[:5]\n",
    "    # loop over the contours\n",
    "    i = 0\n",
    "    for c in cnts:\n",
    "        if (cv.contourArea(c) < h * w * 0.10):\n",
    "            break\n",
    "\n",
    "        # approximate the contour\n",
    "        peri = cv.arcLength(c, True)\n",
    "        approx = cv.approxPolyDP(c, 0.1 * peri, True)\n",
    "        # Contour has 3 points, represents a triangle\n",
    "        if len(approx) == 3:\n",
    "            temp_mask = np.zeros(image_hsv.shape[:2], dtype = np.uint8)\n",
    "            cv.drawContours(temp_mask, cnts, i, (255,255,255), -1)\n",
    "            return temp_mask - background_mask, temp_mask, canny_mask\n",
    "        i+=1\n",
    "    \n",
    "    \n",
    "    mask = cv.inRange(image_hsv, lower_black, upper_black)\n",
    "    mask += cv.inRange(image_hsv, lower_yellow, upper_yellow)\n",
    "    \n",
    "    \n",
    "    final_mask = mask - canny_mask - background_mask\n",
    "    \n",
    "    \n",
    "    return final_mask, mask, canny_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_largest_contour(image, fill = -1):\n",
    "    # Threshold to keep only the bright area in the mask \n",
    "    _, image = cv.threshold(image, 200, 255, cv.THRESH_TOZERO)\n",
    "    \n",
    "    mask = np.zeros(image.shape, dtype = np.uint8)\n",
    "    largest_contour = None\n",
    "    \n",
    "    \n",
    "    # Find all contours\n",
    "    if (int(cv.__version__[0]) > 3):\n",
    "        contours, hierarchy = cv.findContours(image, cv.RETR_LIST, cv.CHAIN_APPROX_SIMPLE)\n",
    "    else:\n",
    "        _, contours, hierarchy = cv.findContours(image, cv.RETR_LIST, cv.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    \n",
    "    # Find and draw largest contour\n",
    "    if len(contours) != 0:\n",
    "        cnt_list = np.zeros(len(contours))\n",
    "        for i in range(0,len(contours)):\n",
    "            cnt_list[i] = cv.contourArea(contours[i])\n",
    "\n",
    "            \n",
    "        largest_contour_index = np.argmax(cnt_list)\n",
    "        largest_contour = contours[largest_contour_index]\n",
    "        cv.drawContours(mask, contours, largest_contour_index, (255,255,255), fill)\n",
    "\n",
    "        \n",
    "    return largest_contour, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bounding_box(image, largest_contour, colour):\n",
    "    bounding_box = image.copy()\n",
    "    \n",
    "    \n",
    "    # If contour is not exists\n",
    "    if (largest_contour is None):\n",
    "        return bounding_box, (0,0,0,0)\n",
    "    \n",
    "    \n",
    "    cv.boundingRect(largest_contour)\n",
    "    x,y,w,h = cv.boundingRect(largest_contour)\n",
    "    cv.rectangle(bounding_box,(x,y),(x+w,y+h),colour,2)\n",
    "    return bounding_box, (x,y,x+w,y+h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest_contour(contours, image):\n",
    "    h, w = image.shape[:2]\n",
    "    center = np.array((int(h/2), int(w/2)))\n",
    "    rect = np.zeros((h, w), dtype = np.uint8)\n",
    "    \n",
    "    \n",
    "    closest = 0\n",
    "    closest_distance = 9999\n",
    "    \n",
    "    \n",
    "    if(contours[0] is not None):\n",
    "        blue_dist = cv.moments(contours[0])\n",
    "        cx = int(blue_dist['m10']/max(blue_dist['m00'], 1))\n",
    "        cy = int(blue_dist['m01']/max(blue_dist['m00'], 1))\n",
    "        blue_distance = ((cx - center[1])**2 + (cy - center[0])**2)**0.5\n",
    "        if blue_distance < closest_distance:\n",
    "            _,_,w0,y0 = cv.boundingRect(contours[0])\n",
    "            if(w0*y0 > h*w*0.2):\n",
    "                closest_distance = blue_distance\n",
    "    \n",
    "    \n",
    "    if(contours[1] is not None):\n",
    "        red_dist = cv.moments(contours[1])\n",
    "        cx = int(red_dist['m10']/max(red_dist['m00'], 1))\n",
    "        cy = int(red_dist['m01']/max(red_dist['m00'], 1))\n",
    "        red_distance = ((cx - center[1])**2 + (cy - center[0])**2)**0.5\n",
    "        if red_distance < closest_distance:\n",
    "            _,_,w1,y1 = cv.boundingRect(contours[1])\n",
    "            if(w1*y1 > h*w*0.2):\n",
    "                closest = 1\n",
    "                closest_distance = red_distance\n",
    "        \n",
    "        \n",
    "    if(contours[2] is not None):\n",
    "        yellow_dist = cv.moments(contours[2])\n",
    "        cx = int(yellow_dist['m10']/max(yellow_dist['m00'], 1))\n",
    "        cy = int(yellow_dist['m01']/max(yellow_dist['m00'], 1))\n",
    "        yellow_distance = ((cx - center[1])**2 + (cy - center[0])**2)**0.5\n",
    "        if yellow_distance < closest_distance:\n",
    "            _,_,w2,y2 = cv.boundingRect(contours[2])\n",
    "            if(w2*y2 > h*w*0.2):\n",
    "                closest = 2\n",
    "        \n",
    "    \n",
    "    return closest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentation(annotation, images, traffic_sign, save_result):\n",
    "    seconds = time.time()\n",
    "    ts = np.where(annotation['Category'].isin(traffic_sign))[0]\n",
    "    combine_all = np.empty((150,1050,3))\n",
    "    bounding_box_points = []\n",
    "    \n",
    "    for i in range (len(ts)):\n",
    "        # Create a copy of the original image\n",
    "        image = images[ts[i]].copy()\n",
    "        h, w = image.shape[:2]\n",
    "        \n",
    "        \n",
    "        # Convert image into hsv colour space and gray colour space\n",
    "        image_hsv = cv.cvtColor(image, cv.COLOR_BGR2HSV)\n",
    "\n",
    "        \n",
    "        # Segment background colour\n",
    "        background_mask = hsv_edges_bg_mask(image_hsv)\n",
    "        \n",
    " \n",
    "        # HSV segmentation\n",
    "        blueseg_mask, blue_mask, blue_canny_mask = blue_seg(image_hsv, image, background_mask)\n",
    "        redseg_mask, red_mask, red_canny_mask = red_seg(image_hsv, image, background_mask)\n",
    "        yellowseg_mask, yellow_mask, yellow_canny_mask = black_seg(image_hsv, image, background_mask)\n",
    "        \n",
    "        \n",
    "        # Find largest contour\n",
    "        blue_largest_contour, blue_largest_contour_mask = find_largest_contour(blueseg_mask)\n",
    "        red_largest_contour, red_largest_contour_mask = find_largest_contour(redseg_mask)\n",
    "        yellow_largest_contour, yellow_largest_contour_mask = find_largest_contour(yellowseg_mask)\n",
    "        \n",
    "        \n",
    "        # Draw bounding box\n",
    "        blue_bounding_box, blue_box_points = draw_bounding_box(image, blue_largest_contour, (255,0,0))\n",
    "        red_bounding_box, red_box_points = draw_bounding_box(image, red_largest_contour, (0,0,255))\n",
    "        yellow_bounding_box, yellow_box_points = draw_bounding_box(image, yellow_largest_contour, (0,255,255))\n",
    "        \n",
    "        \n",
    "        # Find the contour the is closest to the center\n",
    "        contours = [blue_largest_contour, red_largest_contour, yellow_largest_contour]\n",
    "        closest = closest_contour(contours, image)\n",
    "        \n",
    "    \n",
    "        if(closest == 0):\n",
    "            canny_mask = blue_canny_mask\n",
    "            hsv_mask = blue_mask\n",
    "            segmented_mask = blueseg_mask\n",
    "            final_mask = blue_largest_contour_mask\n",
    "            bounding_box = blue_bounding_box\n",
    "            bounding_box_points.append(blue_box_points)\n",
    "        elif (closest == 1):\n",
    "            canny_mask = red_canny_mask\n",
    "            hsv_mask = red_mask\n",
    "            segmented_mask = redseg_mask\n",
    "            final_mask = red_largest_contour_mask\n",
    "            bounding_box = red_bounding_box\n",
    "            bounding_box_points.append(red_box_points)\n",
    "        else:\n",
    "            canny_mask = yellow_canny_mask\n",
    "            hsv_mask = yellow_mask\n",
    "            segmented_mask = yellowseg_mask\n",
    "            final_mask = yellow_largest_contour_mask\n",
    "            bounding_box = yellow_bounding_box\n",
    "            bounding_box_points.append(yellow_box_points)\n",
    "\n",
    "\n",
    "        if(save_result):\n",
    "            canny_mask = np.stack((canny_mask,)*3, axis=-1)\n",
    "            background_mask = np.stack((background_mask,)*3, axis=-1)\n",
    "            hsv_mask = np.stack((hsv_mask,)*3, axis=-1)\n",
    "            segmented_mask = np.stack((segmented_mask,)*3, axis=-1)\n",
    "            final_mask = np.stack((final_mask,)*3, axis=-1)\n",
    "            combine = np.concatenate((image, canny_mask, background_mask, hsv_mask, segmented_mask, final_mask, bounding_box), axis = 1)\n",
    "            combine = cv.resize(combine, (1050,150), interpolation = cv.INTER_AREA)\n",
    "            \n",
    "#             combine = np.concatenate((np.zeros((30, 1050, 3)), combine), axis = 0)\n",
    "#             cv.putText(combine, (\"original image\"), (5, 15), 0, 0.5, (255,255,255), 1, cv.LINE_AA)\n",
    "#             cv.putText(combine, (\"edges detected\"), (155, 15), 0, 0.5, (255,255,255), 1, cv.LINE_AA)\n",
    "#             cv.putText(combine, (\"background\"), (305, 15), 0, 0.5, (255,255,255), 1, cv.LINE_AA)\n",
    "#             cv.putText(combine, (\"HSV mask\"), (455, 15), 0, 0.5, (255,255,255), 1, cv.LINE_AA)\n",
    "#             cv.putText(combine, (\"segmentation\"), (605, 15), 0, 0.5, (255,255,255), 1, cv.LINE_AA)\n",
    "#             cv.putText(combine, (\"largest contour\"), (755, 15), 0, 0.5, (255,255,255), 1, cv.LINE_AA)\n",
    "#             cv.putText(combine, (\"bounding box\"), (905, 15), 0, 0.5, (255,255,255), 1, cv.LINE_AA)\n",
    "            \n",
    "            combine_all = np.concatenate((combine_all, combine), axis = 0)      \n",
    "            if (i%100 == 0):\n",
    "                cv.imwrite('saved' + str(i//100) + '.jpg', combine_all)\n",
    "                combine_all = combine\n",
    "                print(i, \"/\", len(ts), \"Elapsed time:\", time.time() - seconds, \"Average time:\", (time.time() - seconds)/(i+1))\n",
    "        elif (i%100 == 0):\n",
    "            print(i, \"/\", len(ts), \"Elapsed time:\", time.time() - seconds, \"Average time:\", (time.time() - seconds)/(i+1))\n",
    "    \n",
    "    return bounding_box_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Load train annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the train set annotation txt file\n",
    "path = os.path.join(os.getcwd(), 'TSRD-Train Annotation\\\\TsignRecgTrain4170Annotation.txt')\n",
    "\n",
    "# Name of the columns\n",
    "columns = ['File Name', 'Width', 'Height', 'Start_X', 'Start_Y', 'End_X', 'End_Y', 'Category']\n",
    "\n",
    "# Read the content of the train annotation txt file into train_annotation\n",
    "train_annotation = pd.read_csv(path, sep=\";\", index_col = False, names = columns)\n",
    "\n",
    "# One hot encode the category of the images\n",
    "encoder = LabelBinarizer()\n",
    "train_category = encoder.fit_transform(train_annotation['Category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Load train images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path to the folder containing the trains set image files\n",
    "path = os.path.join(os.getcwd(), 'TSRD-train')\n",
    "\n",
    "#read the train images into train_image\n",
    "train_images = []\n",
    "for i in range (train_annotation.shape[0]):\n",
    "    train_images.append(cv.imread(path + '\\\\' + train_annotation.iloc[i][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 4170 Elapsed time: 0.04899430274963379 Average time: 0.04899430274963379\n",
      "100 / 4170 Elapsed time: 1.4099948406219482 Average time: 0.013960344956652953\n",
      "200 / 4170 Elapsed time: 2.846996545791626 Average time: 0.014164161919361323\n",
      "300 / 4170 Elapsed time: 4.362994432449341 Average time: 0.014494998114449638\n",
      "400 / 4170 Elapsed time: 5.798243045806885 Average time: 0.014459458967099463\n",
      "500 / 4170 Elapsed time: 7.175190210342407 Average time: 0.014321736946791232\n",
      "600 / 4170 Elapsed time: 8.623193502426147 Average time: 0.014348075711191594\n",
      "700 / 4170 Elapsed time: 10.071190595626831 Average time: 0.01436689100660033\n",
      "800 / 4170 Elapsed time: 11.49819040298462 Average time: 0.014354794510592534\n",
      "900 / 4170 Elapsed time: 12.895240783691406 Average time: 0.014312142934174701\n",
      "1000 / 4170 Elapsed time: 14.434193134307861 Average time: 0.014419773360946915\n",
      "1100 / 4170 Elapsed time: 15.864241361618042 Average time: 0.014408938566410574\n",
      "1200 / 4170 Elapsed time: 17.307192087173462 Average time: 0.014410651196647346\n",
      "1300 / 4170 Elapsed time: 18.67124104499817 Average time: 0.014351453531897132\n",
      "1400 / 4170 Elapsed time: 20.13324213027954 Average time: 0.01437062250555285\n",
      "1500 / 4170 Elapsed time: 21.460240602493286 Average time: 0.01429729553797021\n",
      "1600 / 4170 Elapsed time: 22.84824228286743 Average time: 0.014271231906850363\n",
      "1700 / 4170 Elapsed time: 24.30819058418274 Average time: 0.014290529443963985\n",
      "1800 / 4170 Elapsed time: 25.905193567276 Average time: 0.01438378321336813\n",
      "1900 / 4170 Elapsed time: 27.35324001312256 Average time: 0.014388869023210184\n",
      "2000 / 4170 Elapsed time: 28.803240537643433 Average time: 0.01439442305729307\n",
      "2100 / 4170 Elapsed time: 30.31119132041931 Average time: 0.014427030614192914\n",
      "2200 / 4170 Elapsed time: 31.79019260406494 Average time: 0.01444352230988866\n",
      "2300 / 4170 Elapsed time: 33.390230894088745 Average time: 0.014511182483306712\n",
      "2400 / 4170 Elapsed time: 34.82224225997925 Average time: 0.014503224598075489\n",
      "2500 / 4170 Elapsed time: 36.27419090270996 Average time: 0.014503874811159521\n",
      "2600 / 4170 Elapsed time: 37.833242893218994 Average time: 0.01454565278478239\n",
      "2700 / 4170 Elapsed time: 39.24219298362732 Average time: 0.014528764525593232\n",
      "2800 / 4170 Elapsed time: 40.758240699768066 Average time: 0.014551317636475568\n",
      "2900 / 4170 Elapsed time: 42.2392418384552 Average time: 0.01456023503566191\n",
      "3000 / 4170 Elapsed time: 43.71419334411621 Average time: 0.014566542267282975\n",
      "3100 / 4170 Elapsed time: 45.18123960494995 Average time: 0.01456989345532085\n",
      "3200 / 4170 Elapsed time: 46.61923122406006 Average time: 0.014563958520481118\n",
      "3300 / 4170 Elapsed time: 48.00519037246704 Average time: 0.014542620530889743\n",
      "3400 / 4170 Elapsed time: 49.3622407913208 Average time: 0.01451403728060006\n",
      "3500 / 4170 Elapsed time: 50.78824162483215 Average time: 0.014506781383842374\n",
      "3600 / 4170 Elapsed time: 52.205429792404175 Average time: 0.014497481197557394\n",
      "3700 / 4170 Elapsed time: 53.63378548622131 Average time: 0.014491701023026564\n",
      "3800 / 4170 Elapsed time: 55.01948618888855 Average time: 0.014475002943669706\n",
      "3900 / 4170 Elapsed time: 56.5464882850647 Average time: 0.014495382795453652\n",
      "4000 / 4170 Elapsed time: 57.932485818862915 Average time: 0.014479501579320899\n",
      "4100 / 4170 Elapsed time: 59.290486335754395 Average time: 0.014457567992137136\n"
     ]
    }
   ],
   "source": [
    "bounding_box_points = segmentation(train_annotation, train_images, all_ts, save_result = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation accuracy: 0.9010446792760016\n"
     ]
    }
   ],
   "source": [
    "total_overlapp = 0\n",
    "area = 0\n",
    "for i in range (len(bounding_box_points)):\n",
    "    area1 = (bounding_box_points[i][2] - bounding_box_points[i][0]) * (bounding_box_points[i][3] - bounding_box_points[i][1])\n",
    "    area2 = (train_annotation['End_X'][i] - train_annotation['Start_X'][i]) * (train_annotation['End_Y'][i] - train_annotation['Start_Y'][i])\n",
    "    X_diff = max(0, min(bounding_box_points[i][2], train_annotation['End_X'][i]) - max(bounding_box_points[i][0], train_annotation['Start_X'][i]))\n",
    "    Y_diff = max(0, min(bounding_box_points[i][3], train_annotation['End_Y'][i]) - max(bounding_box_points[i][1], train_annotation['Start_Y'][i]))\n",
    "    overlapp = X_diff * Y_diff\n",
    "    total_overlapp += overlapp\n",
    "    area = area + area1 + area2 - overlapp\n",
    "print(\"Segmentation accuracy:\", total_overlapp/area)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
